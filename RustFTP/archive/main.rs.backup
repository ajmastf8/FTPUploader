// Database module for SQLite file hash tracking
mod db;

use serde::{Deserialize, Serialize};
use std::fs;
use std::path::PathBuf;
use std::time::{Instant, Duration};
use std::sync::{Arc, Mutex, atomic::{AtomicBool, AtomicUsize, Ordering}};
use rayon::prelude::*;
use crossbeam::channel;
use log::{info, warn, error, debug};
use chrono::Utc;
use colored::*;
use xxhash_rust::xxh3::xxh3_64;

#[derive(Debug, Deserialize, Clone)]
struct FTPConfig {
    pub server_address: String,
    pub port: u16,
    pub username: String,
    pub password: String,
    pub remote_directories: Vec<String>,
    pub local_download_path: String,
    pub respect_file_paths: bool,
    pub download_mode: String,
    pub sync_interval: f64, // How often to run sync cycles (milliseconds from Swift, converted to seconds)
    pub stabilization_interval: u64, // How long to wait for file stabilization (milliseconds from Swift, converted to seconds)
    pub download_aggressiveness: u32, // Number of parallel connections (from Swift enum)
    pub auto_tune_aggressiveness: bool, // Enable/disable auto-tuning of download aggressiveness
    pub config_id: u32,
    pub config_name: String,
    pub session_id: String, // Added: Session ID from Swift
}

#[derive(Debug, Serialize)]
struct FTPStatus {
    pub config_id: u32,
    pub stage: String,
    pub filename: String,
    pub progress: f64,
    pub timestamp: u64,
    pub file_size: Option<u64>, // bytes
    pub download_speed_mbps: Option<f64>, // MB/s for completed downloads
    pub download_time_secs: Option<f64>, // seconds for completed downloads
}

#[derive(Debug, Serialize)]
struct FTPResult {
    pub config_id: u32,
    pub success: bool,
    pub message: String,
    pub files_processed: usize,
    pub timestamp: u64,
}

#[derive(Debug, Serialize)]
struct FTPSessionSummary {
    pub config_id: u32,
    pub config_name: String,
    pub start_time: u64,
    pub end_time: u64,
    pub total_duration_seconds: f64,
    pub files_processed: usize,
    pub total_bytes_downloaded: u64,
    pub average_download_speed_mbps: f64,
    pub peak_download_speed_mbps: f64,
    pub download_speeds: Vec<f64>, // Individual file speeds for analysis
    pub success: bool,
    pub error_message: Option<String>,
}

#[derive(Debug, Serialize)]
struct FTPNotification {
    pub config_id: u32,
    pub notification_type: String, // "success", "info", "warning", "error"
    pub message: String,
    pub timestamp: u64,
    pub filename: Option<String>,
    pub progress: Option<f64>,
}

// Session state tracking for the entire FTP session
#[derive(Debug)]
struct SessionState {
    start_time: Instant,
    total_files: usize,
    total_bytes: usize,
    total_download_time: f64, // seconds
    file_speeds: Vec<f64>, // MB/s for each file
    current_operation: String,
    errors: Vec<String>,
}

impl SessionState {
    fn new() -> Self {
        SessionState {
            start_time: Instant::now(),
            total_files: 0,
            total_bytes: 0,
            total_download_time: 0.0,
            file_speeds: Vec::new(),
            current_operation: "Starting".to_string(),
            errors: Vec::new(),
        }
    }

    fn update_operation(&mut self, operation: &str) {
        self.current_operation = operation.to_string();
    }

    fn add_file_download(&mut self, bytes: usize, download_time: f64) {
        self.total_files += 1;
        self.total_bytes += bytes;
        self.total_download_time += download_time;
        
        // Calculate speed for this file
        if download_time > 0.0 {
            let speed_mbps = (bytes as f64 / 1024.0 / 1024.0) / download_time;
            self.file_speeds.push(speed_mbps);
        }
    }

    fn add_error(&mut self, error: &str) {
        self.errors.push(error.to_string());
    }

    fn get_average_speed_mbps(&self) -> f64 {
        if self.file_speeds.is_empty() {
            return 0.0;
        }
        self.file_speeds.iter().sum::<f64>() / self.file_speeds.len() as f64
    }

    fn get_peak_speed_mbps(&self) -> f64 {
        self.file_speeds.iter().fold(0.0, |max, &speed| max.max(speed))
    }

    fn get_session_duration(&self) -> f64 {
        self.start_time.elapsed().as_secs_f64()
    }

    fn generate_session_report(&self, config: &FTPConfig) -> SessionReport {
        SessionReport {
            session_id: config.session_id.clone(),
            config_id: config.config_id,
            total_files: self.total_files,
            total_bytes: self.total_bytes,
            total_time_secs: self.get_session_duration(),
            average_speed_mbps: self.get_average_speed_mbps(),
        }
    }
}

// Session report sent to Swift every 3rd file
#[derive(Debug, Serialize)]
struct SessionReport {
    pub session_id: String,
    pub config_id: u32,
    pub total_files: usize,
    pub total_bytes: usize,
    pub total_time_secs: f64,
    pub average_speed_mbps: f64,
}

// Internal status update struct for parallel processing
#[derive(Debug, Clone)]
struct StatusUpdate {
    pub stage: String,
    pub filename: String,
    pub progress: f64,
    pub thread_id: u64,
    pub file_size: Option<u64>, // bytes
}

// Connection error analysis and retry management
#[derive(Debug)]
struct ConnectionManager {
    failed_attempts: AtomicUsize,
    last_failure_time: Arc<Mutex<Option<Instant>>>,
    server_limit_detected: AtomicBool,
}

impl ConnectionManager {
    fn new() -> Self {
        ConnectionManager {
            failed_attempts: AtomicUsize::new(0),
            last_failure_time: Arc::new(Mutex::new(None)),
            server_limit_detected: AtomicBool::new(false),
        }
    }
    
    fn is_server_rejection_error(error_msg: &str) -> bool {
        let error_lower = error_msg.to_lowercase();
        error_lower.contains("too many connections") ||
        error_lower.contains("connection limit") ||
        error_lower.contains("max connections") ||
        error_lower.contains("server full") ||
        error_lower.contains("connection refused") ||
        error_lower.contains("service unavailable") ||
        error_lower.contains("421") || // FTP 421 Service not available
        error_lower.contains("530") || // FTP 530 Not logged in
        error_lower.contains("exceeded") ||
        error_lower.contains("busy")
    }
    
    fn is_network_error(error_msg: &str) -> bool {
        let error_lower = error_msg.to_lowercase();
        error_lower.contains("timeout") ||
        error_lower.contains("connection reset") ||
        error_lower.contains("network unreachable") ||
        error_lower.contains("connection lost") ||
        error_lower.contains("broken pipe") ||
        error_lower.contains("connection aborted")
    }
    
    fn record_failure(&self, error_msg: &str, sync_interval: f64) -> (bool, Duration) {
        let attempts = self.failed_attempts.fetch_add(1, Ordering::SeqCst) + 1;
        *self.last_failure_time.lock().unwrap() = Some(Instant::now());

        let is_server_rejection = Self::is_server_rejection_error(error_msg);
        let is_network_issue = Self::is_network_error(error_msg);

        // DEBUG: Log what type of error we detected
        println!("üîç CONNECTION DEBUG: Error='{}' ServerRejection={} NetworkIssue={} Attempt={} SyncInterval={}s",
            error_msg, is_server_rejection, is_network_issue, attempts, sync_interval);

        if is_server_rejection {
            self.server_limit_detected.store(true, Ordering::SeqCst);
        }

        // For very fast sync intervals (< 5s), use much shorter retry delays to avoid blocking
        let use_fast_retry = sync_interval < 5.0;

        // Calculate exponential backoff with jitter
        let base_delay = if use_fast_retry {
            // Fast sync mode: use minimal delays
            if is_server_rejection {
                2 // Server rejections need longer waits, but not too long for fast sync
            } else if is_network_issue {
                1 // Network issues can retry sooner
            } else {
                1 // General connection issues - very fast retry for fast sync
            }
        } else {
            // Normal sync mode: use standard delays
            if is_server_rejection {
                30 // Server rejections need longer waits
            } else if is_network_issue {
                5  // Network issues can retry sooner
            } else {
                10 // General connection issues
            }
        };

        let exponential_delay = if use_fast_retry {
            // For fast sync, limit exponential growth
            base_delay * (1.5_f64.powi((attempts - 1).min(3) as i32) as u64).max(1)
        } else {
            // Standard exponential backoff
            base_delay * (2_u64.pow((attempts - 1).min(6) as u32))
        };

        let jitter = (exponential_delay / 4).max(1);
        // Simple random jitter using system time
        let time_jitter = (std::time::SystemTime::now().duration_since(std::time::UNIX_EPOCH).unwrap().as_nanos() as u64) % jitter;
        let delay = Duration::from_secs(exponential_delay + time_jitter);

        // Cap delays based on sync mode
        let max_delay = if use_fast_retry {
            Duration::from_secs(sync_interval.max(5.0) as u64) // Cap at sync interval or 5s minimum
        } else {
            Duration::from_secs(300) // 5 minutes for normal mode
        };

        println!("üîç RETRY DEBUG: FastRetry={} BaseDelay={}s ExponentialDelay={}s FinalDelay={}s MaxDelay={}s",
            use_fast_retry, base_delay, exponential_delay, delay.as_secs(), max_delay.as_secs());

        (is_server_rejection, delay.min(max_delay))
    }
    
    fn record_success(&self) {
        self.failed_attempts.store(0, Ordering::SeqCst);
        self.server_limit_detected.store(false, Ordering::SeqCst);
        *self.last_failure_time.lock().unwrap() = None;
    }
    
    fn should_reduce_connections(&self) -> bool {
        self.server_limit_detected.load(Ordering::SeqCst)
    }
    
    fn get_failure_count(&self) -> usize {
        self.failed_attempts.load(Ordering::SeqCst)
    }
}

// Helper function to prefix all output with config name
fn config_log(config: &FTPConfig, message: &str) {
    println!("[{}] {}", config.config_name, message);
}

// Helper function to get hash file path for keep mode
fn get_hash_file_path(hash_file: &str) -> Result<PathBuf, Box<dyn std::error::Error>> {
    let path = PathBuf::from(hash_file);
    
    // Ensure directory exists
    if let Some(parent) = path.parent() {
        fs::create_dir_all(parent)?;
    }
    
    Ok(path)
}

// Helper function to get file modification time from FTP server
fn get_file_mod_time(ftp: &mut ftp::FtpStream, filename: &str) -> Result<chrono::DateTime<chrono::Utc>, Box<dyn std::error::Error>> {
    match ftp.mdtm(filename) {
        Ok(Some(time)) => {
            // Convert from chrono v0.2.25 to chrono v0.4.41
            // The FTP crate uses chrono v0.2.25, we use v0.4.41
            let timestamp = time.timestamp();
            let naive = chrono::DateTime::from_timestamp(timestamp, 0)
                .unwrap_or_else(|| chrono::Utc::now())
                .naive_utc();
            Ok(chrono::DateTime::<chrono::Utc>::from_naive_utc_and_offset(naive, chrono::Utc))
        }
        Ok(None) => {
            // If MDTM returns None, return current time as fallback
            Ok(chrono::Utc::now())
        }
        Err(_) => {
            // If MDTM fails, return current time as fallback
            Ok(chrono::Utc::now())
        }
    }
}

// Helper function to compute file metadata hash
// NOTE: mod_time is REQUIRED in the hash to detect when files are re-uploaded with same name/size
// Files are uniquely identified by: remote_dir + filename + size + mod_time
// This allows detecting re-uploads where only the timestamp changes
fn compute_file_hash(filename: &str, remote_dir: &str, size: u64, mod_time: chrono::DateTime<chrono::Utc>) -> u64 {
    let metadata_string = format!("{}|{}|{}|{}", remote_dir, filename, size, mod_time.timestamp());
    xxh3_64(metadata_string.as_bytes())
}

// Structure to hold complete file metadata for hash tracking
#[derive(Debug, Clone)]
struct FileMetadata {
    hash: u64,
    size: u64,
    mod_time: i64,
}

// Helper function to load existing hashes with full metadata
fn load_existing_hashes(hash_file_path: &PathBuf) -> std::collections::HashMap<String, u64> {
    let mut hashes = std::collections::HashMap::new();
    
    println!("üîç HASH LOAD DEBUG: Reading file: {}", hash_file_path.display());
    
    if let Ok(content) = fs::read_to_string(hash_file_path) {
        println!("üîç HASH LOAD DEBUG: File content length: {} bytes", content.len());
        let lines: Vec<&str> = content.lines().collect();
        println!("üîç HASH LOAD DEBUG: File has {} lines", lines.len());
        
        for (line_num, line) in lines.iter().enumerate() {
            if line_num < 3 {
                println!("üîç HASH LOAD DEBUG: Line {}: '{}'", line_num, line);
            }
            
            let parts: Vec<&str> = line.split('|').collect();
            println!("üîç HASH LOAD DEBUG: Line {} has {} parts", line_num, parts.len());
            
            if parts.len() >= 5 {
                // New format: remote_dir|filename|size|mod_time|hash
                let remote_dir = parts[0];
                let filename = parts[1];
                let key = format!("{}|{}", remote_dir, filename);
                if let Ok(hash) = parts[4].parse::<u64>() {
                    hashes.insert(key.clone(), hash);
                    if line_num < 3 {
                        println!("üîç HASH LOAD DEBUG: Loaded key='{}' hash={}", key, hash);
                    }
                } else {
                    println!("üîç HASH LOAD DEBUG: Failed to parse hash from '{}'", parts[4]);
                }
            } else if parts.len() >= 3 {
                // Legacy format: remote_dir|filename|hash (for backward compatibility)
                let remote_dir = parts[0];
                let filename = parts[1];
                let key = format!("{}|{}", remote_dir, filename);
                if let Ok(hash) = parts[2].parse::<u64>() {
                    hashes.insert(key.clone(), hash);
                    if line_num < 3 {
                        println!("üîç HASH LOAD DEBUG: Loaded legacy key='{}' hash={}", key, hash);
                    }
                } else {
                    println!("üîç HASH LOAD DEBUG: Failed to parse legacy hash from '{}'", parts[2]);
                }
            } else {
                println!("üîç HASH LOAD DEBUG: Skipping line {} with {} parts", line_num, parts.len());
            }
        }
    } else {
        println!("üîç HASH LOAD DEBUG: Failed to read file: {}", hash_file_path.display());
    }
    
    println!("üîç HASH LOAD DEBUG: Final loaded hash count: {}", hashes.len());
    hashes
}

// Helper function to load existing hashes with full metadata preserved
fn load_existing_hashes_with_metadata(hash_file_path: &PathBuf) -> std::collections::HashMap<String, FileMetadata> {
    let mut hashes = std::collections::HashMap::new();
    
    if let Ok(content) = fs::read_to_string(hash_file_path) {
        for line in content.lines() {
            let parts: Vec<&str> = line.split('|').collect();
            if parts.len() >= 5 {
                // New format: remote_dir|filename|size|mod_time|hash
                let remote_dir = parts[0];
                let filename = parts[1];
                let key = format!("{}|{}", remote_dir, filename);
                
                if let (Ok(size), Ok(mod_time), Ok(hash)) = (
                    parts[2].parse::<u64>(),
                    parts[3].parse::<i64>(),
                    parts[4].parse::<u64>()
                ) {
                    hashes.insert(key, FileMetadata { hash, size, mod_time });
                }
            } else if parts.len() >= 3 {
                // Legacy format: remote_dir|filename|hash (for backward compatibility)
                let remote_dir = parts[0];
                let filename = parts[1];
                let key = format!("{}|{}", remote_dir, filename);
                if let Ok(hash) = parts[2].parse::<u64>() {
                    // Use defaults for missing metadata
                    hashes.insert(key, FileMetadata { hash, size: 0, mod_time: 0 });
                }
            }
        }
    }
    
    hashes
}

// Helper function to trim hash file if it's too large
fn trim_hash_file_if_needed(hash_file_path: &PathBuf, max_lines: usize) -> Result<(), Box<dyn std::error::Error>> {
    if let Ok(content) = fs::read_to_string(hash_file_path) {
        let lines: Vec<&str> = content.lines().collect();
        let line_count = lines.len();
        
        if line_count > max_lines {
            // Keep only the most recent entries (last max_lines)
            let trimmed_lines: Vec<&str> = lines.into_iter().rev().take(max_lines).collect();
            let trimmed_count = trimmed_lines.len();
            
            // Write back the trimmed content
            let mut file = fs::OpenOptions::new()
                .write(true)
                .truncate(true)
                .open(hash_file_path)?;
            
            use std::io::Write;
            for line in trimmed_lines.iter().rev() { // Reverse back to original order
                file.write_all(format!("{}\n", line).as_bytes())?;
            }
            
            println!("‚úÇÔ∏è Trimmed hash file from {} to {} lines", line_count, trimmed_count);
        }
    }
    
    Ok(())
}

// Helper function to save hash for a file (optimized append-only approach)
fn save_file_hash(hash_file_path: &PathBuf, filename: &str, remote_dir: &str, hash: u64, size: u64, mod_time: chrono::DateTime<chrono::Utc>) -> Result<(), Box<dyn std::error::Error>> {
    use std::sync::{Mutex, OnceLock};
    use std::io::Write;

    // Global mutex for hash file operations to prevent race conditions
    static HASH_FILE_MUTEX: OnceLock<Mutex<()>> = OnceLock::new();
    let mutex = HASH_FILE_MUTEX.get_or_init(|| Mutex::new(()));
    let _lock = mutex.lock().unwrap();

    println!("üîç HASH SAVE DEBUG: Attempting to save hash for {}/{}", remote_dir, filename);
    println!("üîç HASH SAVE DEBUG: Hash file path: {}", hash_file_path.display());
    println!("üîç HASH SAVE DEBUG: Hash file exists before write: {}", hash_file_path.exists());

    // Check if parent directory exists
    if let Some(parent) = hash_file_path.parent() {
        println!("üîç HASH SAVE DEBUG: Parent directory: {}", parent.display());
        println!("üîç HASH SAVE DEBUG: Parent exists: {}", parent.exists());
    }

    // Create the new hash entry
    let new_entry = format!("{}|{}|{}|{}|{}\n", remote_dir, filename, size, mod_time.timestamp(), hash);

    // Append-only approach - much faster for large files
    match fs::OpenOptions::new()
        .create(true)
        .append(true)
        .open(hash_file_path) {
        Ok(mut file) => {
            println!("üîç HASH SAVE DEBUG: Successfully opened hash file for writing");
            match file.write_all(new_entry.as_bytes()) {
                Ok(_) => {
                    println!("üîç HASH SAVE DEBUG: Successfully wrote hash entry");
                    match file.sync_all() {
                        Ok(_) => println!("üîç HASH SAVE DEBUG: Successfully synced file to disk"),
                        Err(e) => println!("‚ö†Ô∏è HASH SAVE WARNING: Failed to sync file: {}", e)
                    }
                    Ok(())
                },
                Err(e) => {
                    println!("‚ùå HASH SAVE ERROR: Failed to write hash entry: {}", e);
                    println!("‚ùå HASH SAVE ERROR: Error kind: {:?}", e.kind());
                    Err(Box::new(e))
                }
            }
        },
        Err(e) => {
            println!("‚ùå HASH SAVE ERROR: Failed to open hash file: {}", e);
            println!("‚ùå HASH SAVE ERROR: Error kind: {:?}", e.kind());
            Err(Box::new(e))
        }
    }
}

// Session stats tracking for download speed calculation
#[derive(Debug)]
struct SessionStats {
    total_bytes: usize,
    total_time: f64, // seconds
    file_count: usize,
    session_start_time: u64, // Unix timestamp when session started
}

impl SessionStats {
    fn new() -> Self {
        SessionStats {
            total_bytes: 0,
            total_time: 0.0,
            file_count: 0,
            session_start_time: std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .unwrap_or_default()
                .as_secs(),
        }
    }

    fn update(&mut self, bytes: usize, time_secs: f64) {
        self.total_bytes += bytes;
        self.total_time += time_secs;
        self.file_count += 1;
    }

    fn average_speed_mbps(&self) -> f64 {
        if self.total_time > 0.0 {
            (self.total_bytes as f64 / 1024.0 / 1024.0) / self.total_time
        } else {
            0.0
        }
    }
    
    fn write_session_json(&self, session_file: &str, config: &FTPConfig) -> Result<(), Box<dyn std::error::Error>> {
        let report = SessionReport {
            session_id: config.session_id.clone(),
            config_id: config.config_id,
            total_files: self.file_count,
            total_bytes: self.total_bytes,
            total_time_secs: self.total_time,
            average_speed_mbps: self.average_speed_mbps(),
        };

        let report_json = serde_json::to_string_pretty(&report)?;
        
        // Debug: Print the session report being written
        config_log(config, &format!("üìä Writing session report to {}: {}", session_file, report_json));
        
        fs::write(session_file, report_json)?;
        
        // Log the session report - always show it, even if stats are 0
        if self.file_count > 0 {
            config_log(config, &format!("üìä Session Report: {} files, {:.2} MB/s", 
                self.file_count.to_string().green(),
                self.average_speed_mbps().to_string().cyan()
            ));
    
        } else {
            config_log(config, &format!("üìä Session Report: No files processed (0 files, 0.00 MB/s)"));
    
        }
        
        Ok(())
    }
}

fn main() -> Result<(), Box<dyn std::error::Error>> {
    // CRITICAL STARTUP DIAGNOSTICS - Write to file BEFORE anything else
    // This will help us understand why the App Store build is crashing
    use std::io::Write;

    // Use FTP_TMP_DIR environment variable for sandboxed apps, fallback to /tmp
    let tmp_dir = std::env::var("FTP_TMP_DIR").unwrap_or_else(|_| "/tmp/".to_string());
    let diagnostic_log = format!("{}rust_ftp_startup.log", tmp_dir);

    let mut diag_file = fs::OpenOptions::new()
        .create(true)
        .append(true)
        .open(&diagnostic_log)
        .unwrap_or_else(|e| {
            eprintln!("FATAL: Cannot create diagnostic log at {}: {}", diagnostic_log, e);
            std::process::exit(1);
        });

    writeln!(diag_file, "\n========== RUST_FTP STARTUP {} ==========", Utc::now().format("%Y-%m-%d %H:%M:%S")).ok();
    writeln!(diag_file, "PID: {}", std::process::id()).ok();
    writeln!(diag_file, "Current directory: {:?}", std::env::current_dir()).ok();
    writeln!(diag_file, "Executable path: {:?}", std::env::current_exe()).ok();
    writeln!(diag_file, "Environment:").ok();
    for (key, value) in std::env::vars() {
        if key.starts_with("FTP") || key.starts_with("HOME") || key.starts_with("USER") || key.starts_with("TMPDIR") {
            writeln!(diag_file, "  {}: {}", key, value).ok();
        }
    }
    writeln!(diag_file, "Arguments: {:?}", std::env::args().collect::<Vec<_>>()).ok();
    diag_file.flush().ok();

    writeln!(diag_file, "Initializing env_logger...").ok();
    diag_file.flush().ok();
    // Initialize logging
    env_logger::init();
    writeln!(diag_file, "‚úÖ env_logger initialized").ok();
    diag_file.flush().ok();

    writeln!(diag_file, "Setting up shutdown signal handling...").ok();
    diag_file.flush().ok();
    // Set up shutdown signal handling
    let shutdown_flag = Arc::new(AtomicBool::new(false));
    let shutdown_flag_clone = shutdown_flag.clone();

    ctrlc::set_handler(move || {
        println!("{} Received shutdown signal, finishing current iteration...", "üõë".red());
        shutdown_flag_clone.store(true, Ordering::SeqCst);
    }).expect("Error setting Ctrl-C handler");
    writeln!(diag_file, "‚úÖ Shutdown signal handler set").ok();
    diag_file.flush().ok();

    writeln!(diag_file, "Parsing command line arguments...").ok();
    diag_file.flush().ok();
    let args: Vec<String> = std::env::args().collect();
    if args.len() < 6 {
        writeln!(diag_file, "‚ùå ERROR: Not enough arguments! Got {} args, need 6", args.len()).ok();
        diag_file.flush().ok();
        eprintln!("{} Usage: {} <config_file> <status_file> <result_file> <session_file> <hash_file>", "‚ùå".red(), args[0]);
        std::process::exit(1);
    }
    writeln!(diag_file, "‚úÖ Got {} arguments", args.len()).ok();
    diag_file.flush().ok();

    let config_file = &args[1];
    let status_file = &args[2];
    let result_file = &args[3];
    let session_file = &args[4];
    let hash_file = &args[5];

    println!("{}", "=".repeat(80).blue());
    println!("üöÄ {} - Production FTP Downloader v1.0.0", "FTP".bold().green());
    println!("{}", "=".repeat(80).blue());
    println!("üìÅ Config file: {}", config_file.cyan());
    println!("üìä Status file: {}", status_file.cyan());
    println!("‚úÖ Result file: {}", result_file.cyan());
    println!("üïê Started at: {}", Utc::now().format("%Y-%m-%d %H:%M:%S UTC"));
    println!("{}", "=".repeat(80).blue());

    // Read config
    let mut config: FTPConfig = serde_json::from_str(&fs::read_to_string(config_file)?)?;
    
    // Convert sync_interval from milliseconds to seconds (Swift sends milliseconds)
    config.sync_interval = config.sync_interval / 1000.0;
    
    // Convert stabilization_interval from milliseconds to seconds (Swift sends milliseconds)
    config.stabilization_interval = config.stabilization_interval / 1000;
    
    info!("üîß Config loaded: {}@{}:{}", config.username, config.server_address, config.port);
    config_log(&config, &format!("üîß {}@{}:{}", config.username.green(), config.server_address.cyan(), config.port.to_string().cyan()));

    // Initialize SQLite database for file hash tracking
    // Database will be stored in Application Support alongside temp files
    let db_path = if hash_file.ends_with(".hash") {
        // Use the same directory as the hash file, but call it file_hashes.db
        let hash_path = PathBuf::from(hash_file);
        if let Some(parent) = hash_path.parent() {
            parent.join("file_hashes.db")
        } else {
            PathBuf::from("file_hashes.db")
        }
    } else {
        PathBuf::from("file_hashes.db")
    };

    // Initialize database (creates tables if needed)
    if let Err(e) = db::init_database(&db_path) {
        config_log(&config, &format!("‚ö†Ô∏è  Database initialization failed: {}, falling back to legacy hash files", e));
        writeln!(diag_file, "‚ö†Ô∏è  Database initialization failed: {}", e).ok();
    } else {
        config_log(&config, &format!("‚úÖ Database initialized at: {}", db_path.display()));
        writeln!(diag_file, "‚úÖ Database initialized at: {}", db_path.display()).ok();

        // Attempt to migrate legacy hash file if it exists
        let hash_path = PathBuf::from(hash_file);
        if hash_path.exists() {
            config_log(&config, &"üîÑ Found legacy hash file, attempting migration...".to_string());
            match db::migrate_from_hash_file(&config.session_id, &hash_path) {
                Ok(count) => {
                    if count > 0 {
                        config_log(&config, &format!("‚úÖ Migrated {} entries from legacy hash file", count));
                        writeln!(diag_file, "‚úÖ Migrated {} entries", count).ok();
                    }
                }
                Err(e) => {
                    config_log(&config, &format!("‚ö†Ô∏è  Migration failed: {}", e));
                    writeln!(diag_file, "‚ö†Ô∏è  Migration failed: {}", e).ok();
                }
            }
        }
    }
    diag_file.flush().ok();

    // Create shutdown file path for this config
    let shutdown_file = format!("{}.shutdown", status_file);
    
    // Helper function to check shutdown status
    let check_shutdown = || {
        if shutdown_flag.load(Ordering::SeqCst) {
            config_log(&config, &format!("{} Shutdown signal received, exiting gracefully", "üõë".red()));
            true
        } else {
            false
        }
    };
    
    // Helper function to check if this specific config should stop
    let check_config_stop = || {
        if fs::metadata(&shutdown_file).is_ok() {
            config_log(&config, &format!("{} Shutdown file detected for config {}, stopping this config", "‚è∏Ô∏è".yellow(), config.config_name));
            true
        } else {
            false
        }
    };
    
    // Log the download mode and sync settings
    config_log(&config, &format!("üîß Download Mode: '{}'", config.download_mode.cyan()));
    config_log(&config, &format!("üîß Sync Interval: {}s (how often to run sync cycles)", config.sync_interval.to_string().green()));
    config_log(&config, &format!("üîß Stabilization Interval: {}s (file stabilization wait)", config.stabilization_interval.to_string().yellow()));
    config_log(&config, &format!("üîß Download Aggressiveness: {} parallel connections", config.download_aggressiveness.to_string().cyan()));
    config_log(&config, &format!("üîß Auto-tune Aggressiveness: {}", if config.auto_tune_aggressiveness { "enabled".green() } else { "disabled".red() }));

    // Send sync interval as notification so it appears in UI
    let _ = send_notification(&config, "info", &format!("üîß Sync Interval: {} seconds", config.sync_interval), None, None);

    if config.sync_interval <= 0.0 {
        config_log(&config, &format!("‚ö†Ô∏è {} Sync interval is 0 - will run once and exit", "WARNING:".red()));
        let _ = send_notification(&config, "warning", "‚ö†Ô∏è Sync interval is 0 - will run once and exit", None, None);
    } else {
        config_log(&config, &format!("üîÑ {} Will run continuously every {}s until stopped", "CONTINUOUS MODE:".green(), config.sync_interval.to_string().green()));
        let _ = send_notification(&config, "info", &format!("üîÑ Continuous mode: will loop every {} seconds", config.sync_interval), None, None);
    }

    // Check if shutdown file exists at startup (debugging)
    if fs::metadata(&shutdown_file).is_ok() {
        config_log(&config, &format!("‚ö†Ô∏è {} SHUTDOWN FILE STILL EXISTS AT STARTUP - this should not happen!", "WARNING:".red()));
        config_log(&config, &format!("‚ö†Ô∏è Shutdown file path: {}", shutdown_file.yellow()));
        config_log(&config, &format!("‚ö†Ô∏è This will cause immediate exit - Swift should have cleared this file!"));
    } else {
        config_log(&config, &format!("‚úÖ {} No shutdown file detected - ready to start continuous sync", "CLEAR:".green()));
    }

    // Send initial status
    send_status(status_file, &config, "Starting", "", 0.0, None)?;

    // Initialize connection manager for retry logic
    let connection_manager = Arc::new(ConnectionManager::new());
    
    // Main continuous processing loop
    let mut iteration = 0;
    loop {
        // Check if shutdown signal received (Ctrl-C)
        if check_shutdown() {
            config_log(&config, &format!("{} Ctrl-C received, exiting completely", "üõë".red()));
            break;
        }
        
        // Check if this specific config should stop
        if check_config_stop() {
            config_log(&config, &format!("{} Config {} stopped, exiting gracefully", "‚è∏Ô∏è".yellow(), config.config_name));
            break;
        }
        
        iteration += 1;
        let _start_time = Instant::now();
        let start_datetime = Utc::now();
        
        println!("üîÑ RUST DEBUG: LOOP CONTINUED - starting iteration {} at {}", iteration, start_datetime.format("%H:%M:%S"));
        config_log(&config, &format!("{} Starting iteration {} at {}", "üîÑ".blue(), iteration, start_datetime.format("%H:%M:%S")));
        
        // Process one iteration
        let result = process_single_iteration(
            &config, 
            status_file, 
            result_file, 
            session_file, 
            hash_file, 
            &shutdown_file, 
            &shutdown_flag,
            &connection_manager
        );
        
        match result {
            Ok(_) => {
                config_log(&config, &format!("{} Iteration {} completed successfully", "‚úÖ".green(), iteration));
            }
            Err(e) => {
                config_log(&config, &format!("{} Iteration {} failed: {}", "‚ùå".red(), iteration, e));
                // Don't exit on errors, just log and continue to next iteration
            }
        }
        
        // Check if we should continue or exit
        config_log(&config, &format!("üîç DEBUG: Checking sync_interval: {}", config.sync_interval));
        if config.sync_interval <= 0.0 {
            config_log(&config, &format!("{} No sync interval configured ({}), exiting after one iteration", "‚èπÔ∏è".yellow(), config.sync_interval));
            break;
        }
        
        config_log(&config, &format!("‚úÖ DEBUG: Sync interval is positive ({}s), loop will continue", config.sync_interval));

        // Send notification about looping
        let _ = send_notification(&config, "info", &format!("‚è≥ Waiting {} seconds before next sync cycle...", config.sync_interval), None, None);

        // Wait for the configured sync interval before next iteration
        config_log(&config, &format!("{} Waiting {} seconds before next sync cycle...", "‚è≥".yellow(), config.sync_interval));
        config_log(&config, &format!("{} Process will stay alive and continue monitoring", "üîÑ".blue()));
        
        // Check for shutdown during interval wait - check every 100ms for faster response
        let wait_ms = (config.sync_interval * 1000.0) as u64; // Convert to milliseconds
        let mut elapsed_ms = 0;
        
        config_log(&config, &format!("üîç DEBUG: Starting interval wait for {} ms", wait_ms));
        
        while elapsed_ms < wait_ms {
            if shutdown_flag.load(Ordering::SeqCst) {
                config_log(&config, &format!("{} Shutdown signal received during interval wait, exiting gracefully", "üõë".red()));
                return Ok(());
            }
            if fs::metadata(&shutdown_file).is_ok() {
                config_log(&config, &format!("{} Shutdown file detected during interval wait, exiting gracefully", "üõë".red()));
                return Ok(());
            }
            std::thread::sleep(std::time::Duration::from_millis(100));
            elapsed_ms += 100;
        }
        
        config_log(&config, &format!("‚úÖ DEBUG: Interval wait completed, continuing to next iteration"));
        
        // Check shutdown flag and shutdown file again after interval
        if shutdown_flag.load(Ordering::SeqCst) {
            config_log(&config, &format!("{} Shutdown signal received after interval, exiting gracefully", "üõë".red()));
            break;
        }
        // Note: We don't check for shutdown file here because it would prevent the loop from working
        // The shutdown file is only checked during the interval wait, not after
        
        // Continue to next iteration
        
        // Continue to next iteration
        config_log(&config, &format!("üîÑ Starting next iteration - will rescan directories for new files"));
        config_log(&config, &format!("üîç DEBUG: About to continue to iteration {}", iteration + 1));
        println!("üîç RUST DEBUG: About to continue to iteration {}", iteration + 1);
        println!("üîÑ RUST DEBUG: LOOP WILL CONTINUE - about to hit the end of loop body");
    }

    println!("üîÑ RUST DEBUG: LOOP ENDED - process exiting");
    config_log(&config, &format!("{} Main loop ended, process exiting", "üèÅ".blue()));
    Ok(())
}

// New function to handle a single iteration of the main loop
fn process_single_iteration(
    config: &FTPConfig,
    status_file: &str,
    result_file: &str,
    session_file: &str,
    hash_file: &str,
    shutdown_file: &str,
    shutdown_flag: &Arc<AtomicBool>,
    connection_manager: &Arc<ConnectionManager>
) -> Result<(), Box<dyn std::error::Error>> {
    
    // Connect to FTP for directory scanning
    config_log(&config, &format!("{} Connecting to FTP server...", "üîå".blue()));
    send_status(status_file, &config, "Connecting", "", 0.1, None)?;
    
    let mut ftp = match ftp::FtpStream::connect((config.server_address.clone(), config.port)) {
        Ok(stream) => {
            config_log(&config, &format!("{} Connected to {}:{}", "‚úÖ".green(), config.server_address, config.port));
            stream
        },
        Err(e) => {
            let error_msg = format!("Connection failed: {}", e);
            error!("{}", error_msg);
            
            // Analyze error and determine retry strategy
            let (is_server_rejection, retry_delay) = connection_manager.record_failure(&error_msg, config.sync_interval);
            let failure_count = connection_manager.get_failure_count();
            
            if is_server_rejection {
                config_log(&config, &format!("{} SERVER REJECTION detected (attempt {}): {}", "üö´".red(), failure_count, error_msg));
                config_log(&config, &format!("{} Server may have connection limits - using exponential backoff", "‚ö†Ô∏è".yellow()));
            } else {
                config_log(&config, &format!("{} Connection failed (attempt {}): {}", "‚ùå".red(), failure_count, error_msg));
            }
            
            config_log(&config, &format!("{} Waiting {:.1} seconds before retry...", "‚è≥".yellow(), retry_delay.as_secs_f64()));
            send_status(status_file, &config, "Error", &format!("Connection failed (attempt {}), retrying in {:.0}s", failure_count, retry_delay.as_secs_f64()), 0.0, None)?;
            write_result(result_file, &config, false, &error_msg, 0)?;

            // Only send notification if this is the 2nd+ failure (don't spam on initial connection)
            if failure_count >= 2 {
                send_notification(&config, "warning", &format!("Connection failed (attempt {}), retrying...", failure_count), None, None)?;
            }

            std::thread::sleep(retry_delay);
            return Ok(()); // Return Ok to continue to next iteration
        }
    };

    if let Err(e) = ftp.login(&config.username, &config.password) {
        let error_msg = format!("Login failed: {}", e);
        error!("{}", error_msg);
        
        // Analyze error and determine retry strategy
        let (is_server_rejection, retry_delay) = connection_manager.record_failure(&error_msg, config.sync_interval);
        let failure_count = connection_manager.get_failure_count();
        
        if is_server_rejection {
            config_log(&config, &format!("{} LOGIN REJECTION detected (attempt {}): {}", "üö´".red(), failure_count, error_msg));
            config_log(&config, &format!("{} Server may be rejecting logins - using exponential backoff", "‚ö†Ô∏è".yellow()));
        } else {
            config_log(&config, &format!("{} Login failed (attempt {}): {}", "‚ùå".red(), failure_count, error_msg));
        }
        
        config_log(&config, &format!("{} Waiting {:.1} seconds before retry...", "‚è≥".yellow(), retry_delay.as_secs_f64()));
        send_status(status_file, &config, "Error", &format!("Login failed (attempt {}), retrying in {:.0}s", failure_count, retry_delay.as_secs_f64()), 0.0, None)?;
        write_result(result_file, &config, false, &error_msg, 0)?;
        
        std::thread::sleep(retry_delay);
        return Ok(()); // Return Ok to continue to next iteration
    }

    // Record successful connection
    connection_manager.record_success();
    let failure_count = connection_manager.get_failure_count();
    
    config_log(&config, &format!("{} Logged in as {} (connection restored after {} failures)",
        "üîë".green(), config.username.green(), failure_count));
    send_status(status_file, &config, "Connected", "", 0.2, None)?;

    // Send structured notification
    send_notification(&config, "info", &format!("Connected to {}", config.server_address), None, None)?;

    // Collect all files from all directories
    let all_files = scan_directories_for_files(&mut ftp, &config, status_file, shutdown_file, shutdown_flag)?;
    
    config_log(&config, &format!("üîç DEBUG: File scan found {} files total (mode: '{}')", all_files.len(), config.download_mode.cyan()));
    for (filename, remote_dir) in &all_files {
        config_log(&config, &format!("  üìÑ Found file: {} in {}", filename.cyan(), remote_dir.yellow()));
    }
    
    // Debug hash tracking behavior based on mode
    if config.download_mode == "keep" {
        config_log(&config, &format!("üîç DEBUG: KEEP mode - will check hashes to avoid re-downloading"));
    } else {
        config_log(&config, &format!("üîç DEBUG: DELETE mode - no hash tracking, will download all files"));
    }
    
    if all_files.is_empty() {
        config_log(&config, &format!("{} No files found to process, will wait for interval and retry", "‚ö†Ô∏è".yellow()));

        // Send structured notification
        send_notification(&config, "info", "No new files found", None, None)?;

        // Close the main FTP connection since we're not using it
        ftp.quit().ok();

        // Write result for this iteration
        write_result(result_file, &config, true, "No files found, completed scan", 0)?;

        // Send completion status
        send_status(status_file, &config, "Complete", "No files found, will retry after interval", 1.0, None)?;

        config_log(&config, &format!("{} SCAN INTERVAL COMPLETE!", "‚úÖ".green()));
        return Ok(());
    }
    
    // Process files if any were found
    // Check if we should reduce parallel connections due to server limits
    let max_connections = if connection_manager.should_reduce_connections() {
        let reduced = (config.download_aggressiveness as usize / 4).max(1); // Reduce to 1/4 of configured aggressiveness
        config_log(&config, &format!("{} Server limit detected - reducing from {} to {} parallel connections", 
            "üîß".yellow(), config.download_aggressiveness, reduced));
        reduced
    } else {
        // TODO: Implement auto-tuning logic using config.auto_tune_aggressiveness
        // For now, just use the configured aggressiveness
        config.download_aggressiveness as usize // Use configured aggressiveness
    };
    
    let files_processed = process_files(
        &mut ftp, 
        &all_files, 
        &config, 
        status_file, 
        session_file, 
        hash_file, 
        shutdown_file,
        shutdown_flag,
        connection_manager,
        max_connections
    )?;
    
    // Close FTP connection
    ftp.quit().ok();
    
    // Write final result
    write_result(result_file, &config, true, "FTP process completed successfully", files_processed)?;
    
    config_log(&config, &format!("{} SCAN INTERVAL COMPLETE!", "‚úÖ".green()));
    Ok(())
}

// Function to scan directories for files
fn scan_directories_for_files(
    ftp: &mut ftp::FtpStream,
    config: &FTPConfig,
    status_file: &str,
    shutdown_file: &str,
    shutdown_flag: &Arc<AtomicBool>
) -> Result<Vec<(String, String)>, Box<dyn std::error::Error>> {
    
    config_log(&config, &format!("{} Scanning directories for files...", "üîç".blue()));
    let mut all_files = Vec::new();
    
    for (dir_index, remote_dir) in config.remote_directories.iter().enumerate() {
        // Check for shutdown during directory scanning
        if shutdown_flag.load(Ordering::SeqCst) {
            if fs::metadata(shutdown_file).is_ok() {
                config_log(&config, &format!("{} Config {} stopped during directory scanning, skipping this directory", "‚è∏Ô∏è".yellow(), config.config_name));
                continue; // Skip this directory, don't exit
            } else {
                config_log(&config, &format!("{} Shutdown during directory scanning, exiting gracefully", "üõë".red()));
                return Ok(all_files); // Return what we have so far
            }
        }
        
        // CRITICAL FIX: Reset to root directory before each scan to prevent CWD drift
        if let Err(e) = ftp.cwd("/") {
            config_log(&config, &format!("‚ö†Ô∏è Warning: Failed to reset to root directory: {}", e));
        }
        
        let progress = 0.2 + (0.3 * (dir_index as f64) / (config.remote_directories.len() as f64));
        config_log(&config, &format!("{} Scanning directory: {} (reset to root first)", "üìÅ".blue(), remote_dir.cyan()));
        send_status(status_file, &config, "Scanning", remote_dir, progress, None)?;

        // Send structured notification
        send_notification(&config, "info", &format!("Scanning {}", remote_dir), None, None)?;

        if let Err(_) = ftp.cwd(remote_dir) {
            warn!("Directory not found: {}", remote_dir);
            config_log(&config, &format!("{} Directory not found: {}", "‚ö†Ô∏è".yellow(), remote_dir.red()));
            send_status(status_file, &config, "Warning", &format!("Directory not found: {}", remote_dir), progress, None)?;

            // Send structured notification
            send_notification(&config, "warning", &format!("Directory not found: {}", remote_dir), None, None)?;
            continue;
        }

        let files = match ftp.list(Some(remote_dir)) {
            Ok(files) => files,
            Err(_) => {
                warn!("Failed to list directory: {}", remote_dir);
                config_log(&config, &format!("{} Failed to list directory: {}", "‚ö†Ô∏è".yellow(), remote_dir.red()));
                send_status(status_file, &config, "Warning", &format!("Failed to list: {}", remote_dir), progress, None)?;
                continue;
            }
        };

        // DEBUG: Log first few raw LIST entries
        config_log(&config, &format!("üîç RAW LIST DEBUG: Total {} entries", files.len()));
        for (idx, entry) in files.iter().take(5).enumerate() {
            config_log(&config, &format!("  RAW[{}]: '{}'", idx, entry));
        }

        // Filter files and collect with directory info
        let filtered: Vec<(String, String)> = files.iter()
            .filter_map(|entry| {
                let trimmed = entry.trim();
                if trimmed.is_empty() {
                    return None;
                }
                
                // Detect listing format based on entry structure (works for Rumpus and other servers)
                let (is_directory, filename) = if trimmed.starts_with('d') {
                    // UNIX-style: drwxr-xr-x 2 user group 4096 Jan 1 12:00 dirname
                    let parts: Vec<&str> = trimmed.split_whitespace().collect();
                    if parts.len() >= 9 {
                        let is_dir = parts[0].starts_with('d');
                        let name = parts[8..].join(" ");
                        (is_dir, name)
                    } else {
                        // Fallback: if it doesn't start with 'd', assume it's a file
                        (false, trimmed.to_string())
                    }
                } else if trimmed.starts_with('-') {
                    // UNIX-style file listing: various formats
                    // Format 1: -rw-r--r-- 1 user group 1234 Oct 26 12:00 filename.txt
                    // Format 2: -rw-rw-rw- 0 3080164 3080164 Jul 11 23:06 filename.txt
                    let parts: Vec<&str> = trimmed.split_whitespace().collect();

                    // Find where the filename starts by looking for the time field
                    // Time is usually in format HH:MM or YYYY (for old files)
                    let mut filename_start_idx = 8; // Default for standard format

                    for (i, part) in parts.iter().enumerate() {
                        if i >= 5 && (part.contains(':') || (part.len() == 4 && part.chars().all(|c| c.is_digit(10)))) {
                            // Found time field (HH:MM or YYYY), filename starts after it
                            filename_start_idx = i + 1;
                            break;
                        }
                    }

                    if parts.len() > filename_start_idx {
                        // Join all parts from filename_start_idx onwards (handles spaces)
                        let name = parts[filename_start_idx..].join(" ");
                        // DEBUG: Only log files with "Olivola" or "Chris" to reduce noise
                        if trimmed.contains("Olivola") || trimmed.contains("Chris") {
                            println!("[{}] üêõ PARSE DEBUG: parts.len()={}, filename_start_idx={}, extracted name='{}'",
                                config.config_name, parts.len(), filename_start_idx, name);
                            println!("[{}] üêõ PARSE DEBUG: raw entry: '{}'", config.config_name, trimmed);
                        }
                        (false, name)
                    } else if parts.len() >= 6 {
                        // Fallback: last part is filename
                        let name = parts[parts.len() - 1];
                        (false, name.to_string())
                    } else {
                        (false, trimmed.to_string())
                    }
                } else if trimmed.contains(' ') && !trimmed.contains('\t') {
                    // Mac OS-style or simple format: check if it looks like a directory
                    let parts: Vec<&str> = trimmed.split_whitespace().collect();
                    if parts.len() >= 2 {
                        // Check if first part looks like permissions, size, or date
                        let first_part = parts[0];
                        let is_dir = first_part.starts_with('d') || 
                                    first_part.parse::<u64>().is_ok() || // Size
                                    first_part.contains('-') || // Date
                                    first_part.contains('/'); // Date
                        
                        if is_dir {
                            (true, parts[1..].join(" "))
                        } else {
                            (false, trimmed.to_string())
                        }
                    } else {
                        // Single item - assume file if no spaces
                        (false, trimmed.to_string())
                    }
                } else {
                    // Simple format: just the name
                    // Check if it looks like a directory (no extension, no dots)
                    let is_dir = !trimmed.contains('.') && !trimmed.contains('\t');
                    (is_dir, trimmed.to_string())
                };
                
                // Skip directories, hidden files, and system files
                if is_directory || 
                   filename.starts_with('.') || 
                   filename.ends_with(".filepart") ||
                   filename.starts_with("._") ||  // macOS resource fork files
                   filename.starts_with("Thumbs.db") ||  // Windows thumbnail cache
                   filename.starts_with(".DS_Store") ||  // macOS system files
                   filename.starts_with(".Trash") ||     // macOS trash
                   filename.starts_with("desktop.ini") || // Windows system files
                   filename.starts_with("~$") ||         // Temporary Office files
                   filename.ends_with(".tmp") ||         // Temporary files
                   filename.ends_with(".temp") {         // Temporary files
                    return None;
                }
                
                Some((filename, remote_dir.clone()))
            })
            .collect();

        let file_count = filtered.len();
        all_files.extend(filtered);
        config_log(&config, &format!("{} Found {} files in {}", "üìä".green(), file_count.to_string().green(), remote_dir.cyan()));
        send_status(status_file, &config, "Found files", &format!("{} files in {}", file_count, remote_dir), progress + 0.1, None)?;

        // Send structured notification
        if file_count > 0 {
            send_notification(&config, "info", &format!("Found {} files in {}", file_count, remote_dir), None, None)?;
        }
    }

    // Mark all discovered files as "seen" in the database and cleanup stale entries
    if config.download_mode == "keep" && !all_files.is_empty() {
        config_log(&config, &format!("üîÑ Updating database with {} discovered files...", all_files.len()));

        // Get current timestamp for cleanup
        let scan_timestamp = chrono::Utc::now().timestamp();

        // Mark each discovered file as seen
        let mut marked_count = 0;
        for (filename, remote_dir) in &all_files {
            if let Err(e) = db::mark_file_seen(&config.session_id, remote_dir, filename) {
                config_log(&config, &format!("‚ö†Ô∏è Failed to mark file as seen: {}/{}: {}", remote_dir, filename, e));
            } else {
                marked_count += 1;
            }
        }

        if marked_count > 0 {
            config_log(&config, &format!("‚úÖ Marked {} files as seen in database", marked_count));
        }

        // Cleanup files that weren't seen in this scan (deleted from server)
        // Use scan_timestamp - 60 seconds to account for scan duration and clock skew
        let cleanup_threshold = scan_timestamp - 60;
        match db::cleanup_stale_files(&config.session_id, cleanup_threshold) {
            Ok(deleted_count) => {
                if deleted_count > 0 {
                    config_log(&config, &format!("üßπ Removed {} stale file entries from database (no longer on server)", deleted_count));
                }
            }
            Err(e) => {
                config_log(&config, &format!("‚ö†Ô∏è Failed to cleanup stale files: {}", e));
            }
        }
    }

    config_log(&config, &format!("{} Total files to process: {}", "üéØ".blue(), all_files.len().to_string().bold().green()));
    Ok(all_files)
}

// Helper function to monitor a single file for stability
// Returns Some((filename, remote_dir, size)) if file is stable, None if still changing
fn monitor_file_stability(
    filename: &str,
    remote_dir: &str,
    config: &FTPConfig,
    connection_manager: &Arc<ConnectionManager>,
) -> Option<(String, String, usize)> {
    // Create FTP connection using connection manager
    let mut ftp = match connection_manager.create_connection(config) {
        Ok(connection) => connection,
        Err(e) => {
            config_log(&config, &format!("‚ö†Ô∏è Failed to create connection for stability check of {}: {}", filename, e));
            return None;
        }
    };

    // Navigate to remote directory
    if let Err(e) = ftp.cwd(remote_dir) {
        config_log(&config, &format!("‚ö†Ô∏è Failed to navigate to {} for {}: {}", remote_dir, filename, e));
        return None;
    }

    // Get initial file size
    let initial_size = match ftp.size(filename) {
        Ok(Some(size)) => size as usize,
        _ => {
            config_log(&config, &format!("‚ö†Ô∏è Failed to get size for {}", filename));
            return None;
        }
    };

    // Wait for stabilization interval
    std::thread::sleep(std::time::Duration::from_secs(config.stabilization_interval));

    // Check final size
    let final_size = match ftp.size(filename) {
        Ok(Some(size)) => size as usize,
        _ => initial_size,
    };

    // If size changed, file is still being written
    if initial_size != final_size {
        config_log(&config, &format!("‚è≠Ô∏è {} still changing ({} -> {} bytes), skipping",
            filename.yellow(),
            initial_size,
            final_size
        ));
        return None;
    }

    // File is stable - return it
    config_log(&config, &format!("‚úÖ {} stable at {} bytes", filename.green(), final_size));
    Some((filename.to_string(), remote_dir.to_string(), final_size))
}

// Function to process files
fn process_files(
    _ftp: &mut ftp::FtpStream, // Unused - each thread creates own connection
    all_files: &[(String, String)],
    config: &FTPConfig,
    status_file: &str,
    session_file: &str,
    hash_file: &str,
    shutdown_file: &str,
    shutdown_flag: &Arc<AtomicBool>,
    connection_manager: &Arc<ConnectionManager>,
    max_parallel_connections: usize
) -> Result<usize, Box<dyn std::error::Error>> {
    
    // Initialize session state tracking
    let session_state = Arc::new(Mutex::new(SessionState::new()));
    
    // Hash-based file discovery for keep mode
    let files_to_process = all_files.to_vec();
    
    if config.download_mode == "keep" {
        config_log(&config, &format!("üîç Keep mode enabled - checking existing file hashes from database..."));

        // Load existing hashes from database instead of file
        match db::load_hashes_for_config(&config.session_id) {
            Ok(existing_hashes) => {
                config_log(&config, &format!("üìã Loaded {} existing file hashes from database", existing_hashes.len()));

                // Filter out files that haven't changed based on hash comparison
                let _original_count = files_to_process.len();

                // For keep mode, we need to check each file's current hash against existing hashes
                // This will be done during the parallel processing phase
                config_log(&config, &format!("üîç Will check {} files against {} existing hashes during processing",
                    files_to_process.len(), existing_hashes.len()));
            }
            Err(e) => {
                config_log(&config, &format!("‚ö†Ô∏è Failed to load hashes from database: {}, continuing without hash tracking", e));
            }
        }
    } else {
        config_log(&config, &format!("üóëÔ∏è Delete mode enabled - will only process files that still exist on server"));
    }
    
    send_status(status_file, &config, "Preparing parallel processing", &format!("{} total files", files_to_process.len()), 0.5, None)?;

    // Process files in parallel using rayon
    let files_processed = Arc::new(AtomicUsize::new(0));
    let status_sender = Arc::new(Mutex::new(status_file.to_string()));
    let config_arc = Arc::new(config.clone());
    let status_sender_clone = status_sender.clone();
    let config_arc_clone = config_arc.clone();

    // Create a channel for status updates from parallel workers
    let (status_tx, status_rx) = channel::unbounded::<StatusUpdate>();
    
    // Spawn status receiver thread
    let status_receiver = std::thread::spawn(move || {
        while let Ok(status_update) = status_rx.recv() {
            if let Ok(status_file) = status_sender.lock() {
                
                // Handle FileComplete messages specially - log them instead of overwriting status
                if status_update.stage == "FileComplete" {
                    // Log the completion message (this will be picked up by Swift)
                    config_log(&config_arc, &status_update.filename);
                    
                    // Still send a status update but with a different stage to avoid overwriting
                    let status = FTPStatus {
                        config_id: config_arc.config_id,
                        stage: "Processing".to_string(), // Don't overwrite main status
                        filename: "Files downloading...".to_string(),
                        progress: status_update.progress,
                        timestamp: std::time::SystemTime::now()
                            .duration_since(std::time::UNIX_EPOCH)
                            .unwrap_or_default()
                            .as_secs(),
                        file_size: status_update.file_size,
                        download_speed_mbps: None,
                        download_time_secs: None,
                    };
                    
                    if let Ok(status_json) = serde_json::to_string(&status) {
                        let _ = fs::write(&**status_file, status_json);
                    }
                } else {
                    // Handle normal status updates
                    let status = FTPStatus {
                        config_id: config_arc.config_id,
                        stage: status_update.stage.clone(),
                        filename: status_update.filename.clone(),
                        progress: status_update.progress,
                        timestamp: std::time::SystemTime::now()
                            .duration_since(std::time::UNIX_EPOCH)
                            .unwrap_or_default()
                            .as_secs(),
                        file_size: status_update.file_size,
                        download_speed_mbps: None, // Will be filled by specific status updates
                        download_time_secs: None,  // Will be filled by specific status updates
                    };
                    
                    if let Ok(status_json) = serde_json::to_string(&status) {
                        let _ = fs::write(&**status_file, status_json);
                    }
                }
            }
        }
    });

    // Create custom thread pool with exactly max_parallel_connections threads
    // This ensures we respect the user's download aggressiveness setting for BOTH stabilization and download
    let pool = rayon::ThreadPoolBuilder::new()
        .num_threads(max_parallel_connections)
        .build()
        .map_err(|e| format!("Failed to create thread pool: {}", e))?;

    config_log(&config, &format!("{} Starting parallel processing with {} worker threads...", "‚ö°".blue(), max_parallel_connections.to_string().green()));
    config_log(&config, &format!("{}", "=".repeat(80).blue()));

    // PHASE 1: Stabilization monitoring (if enabled)
    let files_to_download = if config.stabilization_interval > 0 {
        config_log(&config, &format!("{} Phase 1: Monitoring {} files for stability ({}s interval)...",
            "üîç".cyan(),
            files_to_process.len().to_string().green(),
            config.stabilization_interval.to_string().yellow()
        ));

        let stabilization_start = std::time::Instant::now();
        let connection_manager_clone = connection_manager.clone();
        let config_clone = config.clone();

        // Monitor all files in parallel for stability using custom thread pool
        let stable_files: Vec<(String, String, usize)> = pool.install(|| {
            files_to_process
                .par_iter()
                .filter_map(|(filename, remote_dir)| {
                    monitor_file_stability(filename, remote_dir, &config_clone, &connection_manager_clone)
                })
                .collect()
        });

        let stabilization_elapsed = stabilization_start.elapsed();
        let stabilized_count = stable_files.len();
        let skipped_count = files_to_process.len() - stabilized_count;

        config_log(&config, &format!("{} Phase 1 complete: {} files stabilized, {} still changing (took {:.1}s)",
            "‚úÖ".green(),
            stabilized_count.to_string().green(),
            skipped_count.to_string().yellow(),
            stabilization_elapsed.as_secs_f64()
        ));

        if stabilized_count == 0 {
            config_log(&config, &format!("{} No stable files to download, ending session", "‚ö†Ô∏è".yellow()));
            return Ok(());
        }

        config_log(&config, &format!("{}", "=".repeat(80).blue()));
        config_log(&config, &format!("{} Phase 2: Parallel downloading {} stable files...",
            "‚¨áÔ∏è".blue(),
            stabilized_count.to_string().green()
        ));

        // Convert stable files back to (filename, remote_dir) tuples for download phase
        stable_files.into_iter()
            .map(|(filename, remote_dir, _size)| (filename, remote_dir))
            .collect()
    } else {
        // No stabilization - download all discovered files
        files_to_process.clone()
    };

    // Use the session state tracking already initialized above
    let session_state_clone = session_state.clone();
    
    // Process files in parallel
    let existing_hashes_clone = if config.download_mode == "keep" {
        // Load existing hashes from database instead of file
        match db::load_hashes_for_config(&config.session_id) {
            Ok(hashes) => {
                config_log(&config, &format!("{} Loaded {} existing hashes from database",
                    "üìã".blue(),
                    hashes.len().to_string().green()
                ));

                // DEBUG: Show first few loaded hashes
                let mut count = 0;
                for (key, hash) in &hashes {
                    if count < 3 {
                        config_log(&config, &format!("üîç LOADED HASH DEBUG: Key='{}' Hash={}", key.cyan(), hash));
                        count += 1;
                    }
                }

                hashes
            },
            Err(e) => {
                config_log(&config, &format!("{} Failed to load hashes from database: {}", "‚ö†Ô∏è".yellow(), e));
                std::collections::HashMap::new()
            },
        }
    } else {
        std::collections::HashMap::new()
    };

    // Clone shutdown_file for parallel processing
    let shutdown_file_str = shutdown_file.to_string();

    // Configure parallel processing with adaptive connection limits
    config_log(&config, &format!("üîß Processing with {} parallel connections", max_parallel_connections));

    // Create custom thread pool with exactly max_parallel_connections threads
    // This ensures we respect the user's download aggressiveness setting
    let pool = rayon::ThreadPoolBuilder::new()
        .num_threads(max_parallel_connections)
        .build()
        .map_err(|e| format!("Failed to create thread pool: {}", e))?;

    // Use custom thread pool instead of global pool to respect connection limit
    let results: Vec<Result<(), String>> = pool.install(|| {
        files_to_download
            .par_iter()
            .with_max_len(1) // Each file gets its own task
            .enumerate()
            .map(|(file_index, (filename, remote_dir))| {
        // Check for shutdown before processing each file
        if shutdown_flag.load(Ordering::SeqCst) {
            // Only exit if shutdown file also exists for this config
            if fs::metadata(&shutdown_file_str).is_ok() {
                return Err("Shutdown requested".to_string());
            }
            // If only general shutdown flag is set (Ctrl-C), continue processing this iteration
        }
        
        let thread_id = file_index as u64;
        let file_progress = 0.5 + (0.4 * (file_index as f64) / (files_to_download.len() as f64));
        let existing_hashes = existing_hashes_clone.clone();
        let session_file = session_file.to_string(); // Convert to String for parallel processing
        let _status_sender_local = status_sender_clone.clone();
        let config_arc_local = config_arc_clone.clone();
        let connection_manager_local = connection_manager.clone();
        
        // DEBUG: Log file processing start
        config_log(&config, &format!("üîç DEBUG: [Thread-{}] Starting to process {} ({}/{})",
            thread_id, filename.cyan(), (file_index + 1), files_to_download.len()));
        
        // Send status update
        let _ = status_tx.send(StatusUpdate {
            stage: "Processing".to_string(),
            filename: filename.clone(),
            progress: file_progress,
            thread_id,
            file_size: None,
        });

        // DEBUG: Log FTP connection attempt
        // File processing with connection retry loop
        let max_connection_retries = 3;
        let mut connection_attempt = 0;
        
        let file_result = loop {
            connection_attempt += 1;
            
            config_log(&config, &format!("üîó DEBUG: [Thread-{}] Attempting FTP connection for {} (attempt {})", 
                thread_id, filename.cyan(), connection_attempt));
            
            // Create new FTP connection for this thread
            let mut ftp = match ftp::FtpStream::connect((config.server_address.clone(), config.port)) {
            Ok(stream) => {
                debug!("[Thread-{}] FTP connection established", thread_id);
                config_log(&config, &format!("‚úÖ DEBUG: [Thread-{}] FTP connection successful for {}", thread_id, filename.green()));
                stream
            },
            Err(e) => {
                let error_msg = format!("Failed to connect: {}", e);
                error!("[Thread-{}] {}", thread_id, error_msg);
                
                // Record connection failure in connection manager
                let (is_server_rejection, retry_delay) = connection_manager_local.record_failure(&error_msg, config.sync_interval);
                let failure_count = connection_manager_local.get_failure_count();
                
                if is_server_rejection {
                    config_log(&config, &format!("{} [Thread-{}] SERVER REJECTION on file connection (attempt {}): {}", 
                        "üö´".red(), thread_id, failure_count, error_msg));
                } else {
                    config_log(&config, &format!("{} [Thread-{}] Connection failed (attempt {}): {}", 
                        "‚ùå".red(), thread_id, failure_count, error_msg));
                }
                
                config_log(&config, &format!("‚ùå DEBUG: [Thread-{}] FTP connection FAILED for {}: {}", thread_id, filename.red(), e));
                let _ = status_tx.send(StatusUpdate {
                    stage: if is_server_rejection { "Server Rejection" } else { "Connection failed" }.to_string(),
                    filename: filename.clone(),
                    progress: file_progress,
                    thread_id,
                    file_size: None,
                });
                
                // Check if we should retry
                if connection_attempt >= max_connection_retries {
                    config_log(&config, &format!("{} [Thread-{}] Max connection retries ({}) reached for {}, giving up", 
                        "‚ùå".red(), thread_id, max_connection_retries, filename.red()));
                    break Err(format!("Failed to connect after {} attempts: {}", max_connection_retries, e));
                }
                
                config_log(&config, &format!("{} [Thread-{}] Will retry connection for {} in {:.1}s", 
                    "üîÑ".yellow(), thread_id, filename.yellow(), retry_delay.as_secs_f64()));
                std::thread::sleep(retry_delay);
                continue; // Retry the connection
            }
        };

        // DEBUG: Log login attempt
        config_log(&config, &format!("üîê DEBUG: [Thread-{}] Attempting FTP login for {}", thread_id, filename.cyan()));
        
        if let Err(e) = ftp.login(&config.username, &config.password) {
            let error_msg = format!("Failed to login: {}", e);
            error!("[Thread-{}] {}", thread_id, error_msg);
            
            // Record login failure in connection manager
            let (is_server_rejection, retry_delay) = connection_manager_local.record_failure(&error_msg, config.sync_interval);
            let failure_count = connection_manager_local.get_failure_count();
            
            if is_server_rejection {
                config_log(&config, &format!("{} [Thread-{}] LOGIN REJECTION on file connection (attempt {}): {}", 
                    "üö´".red(), thread_id, failure_count, error_msg));
                config_log(&config, &format!("{} [Thread-{}] 421 Service not available - will logout and reconnect", 
                    "üîÑ".yellow(), thread_id));
            } else {
                config_log(&config, &format!("{} [Thread-{}] Login failed (attempt {}): {}", 
                    "‚ùå".red(), thread_id, failure_count, error_msg));
            }
            
            config_log(&config, &format!("‚ùå DEBUG: [Thread-{}] FTP login FAILED for {}: {}", thread_id, filename.red(), e));
            let _ = status_tx.send(StatusUpdate {
                stage: if is_server_rejection { "Login Rejection" } else { "Login failed" }.to_string(),
                filename: filename.clone(),
                progress: file_progress,
                thread_id,
                file_size: None,
            });
            
            // Clean up connection gracefully
            ftp.quit().ok();
            
            // Check if we should retry
            if connection_attempt >= max_connection_retries {
                config_log(&config, &format!("{} [Thread-{}] Max login retries ({}) reached for {}, giving up", 
                    "‚ùå".red(), thread_id, max_connection_retries, filename.red()));
                break Err(format!("Failed to login after {} attempts: {}", max_connection_retries, e));
            }
            
            config_log(&config, &format!("{} [Thread-{}] Will retry login for {} in {:.1}s", 
                "üîÑ".yellow(), thread_id, filename.yellow(), retry_delay.as_secs_f64()));
            std::thread::sleep(retry_delay);
            continue; // Retry the connection and login
        }
        
        config_log(&config, &format!("‚úÖ DEBUG: [Thread-{}] FTP login successful for {}", thread_id, filename.green()));

        // DEBUG: Log directory change attempt
        config_log(&config, &format!("üìÅ DEBUG: [Thread-{}] Attempting to change to directory '{}' for {}", 
            thread_id, remote_dir.cyan(), filename.cyan()));
        
        // Change to directory
        if let Err(e) = ftp.cwd(remote_dir) {
            let error_msg = format!("Failed to change to directory: {}", remote_dir);
            error!("[Thread-{}] {}", thread_id, error_msg);
            config_log(&config, &format!("‚ùå DEBUG: [Thread-{}] Server rejected CWD to '{}': {}", 
                thread_id, remote_dir.red(), e));
            return Err(error_msg);
        }
        
        config_log(&config, &format!("‚úÖ DEBUG: [Thread-{}] Successfully changed to directory '{}'", 
            thread_id, remote_dir.green()));

        // Check file size for stabilization
        // CRITICAL FIX: Set to BINARY mode before SIZE command (some servers reject SIZE in ASCII mode)
        if let Err(e) = ftp.transfer_type(ftp::types::FileType::Binary) {
            config_log(&config, &format!("‚ö†Ô∏è DEBUG: [Thread-{}] Failed to set BINARY mode: {}", thread_id, e));
        } else {
            config_log(&config, &format!("‚úÖ DEBUG: [Thread-{}] Set BINARY mode for SIZE command", thread_id));
        }
        
        // DEBUG: Log before file size check
        config_log(&config, &format!("üìè DEBUG: [Thread-{}] Checking file size for {}", thread_id, filename.cyan()));
        
        let initial_size = match ftp.size(filename) {
            Ok(Some(size)) => {
                debug!("[Thread-{}] File {} size: {} bytes", thread_id, filename, size);
                config_log(&config, &format!("‚úÖ DEBUG: [Thread-{}] Server reports {} size: {} bytes", 
                    thread_id, filename.green(), size));
                size
            },
            Ok(None) => {
                // File no longer exists on server - skip it
                config_log(&config, &format!("{} [Thread-{}] {} no longer exists on server, skipping", 
                    "‚è≠Ô∏è".yellow(), 
                    thread_id.to_string().cyan(), 
                    filename.green()
                ));
                config_log(&config, &format!("‚ùå DEBUG: [Thread-{}] Server says {} not found (SIZE returned None)", 
                    thread_id, filename.red()));
                return Ok(()); // Skip this file, don't treat as error
            },
            Err(e) => {
                config_log(&config, &format!("‚ùå DEBUG: [Thread-{}] Server error getting size for {}: {}", 
                    thread_id, filename.red(), e));
                return Err(format!("Failed to get size for {}: {}", filename, e));
            },
        };

        // Hash checking for keep mode - do this BEFORE stabilization
        if config.download_mode == "keep" {
            let key = format!("{}|{}", remote_dir, filename);
            // Get file modification time for hash computation
            let mod_time = match get_file_mod_time(&mut ftp, filename) {
                Ok(time) => time,
                Err(_) => chrono::Utc::now(), // Fallback to current time
            };
            let current_hash = compute_file_hash(filename, remote_dir, initial_size as u64, mod_time);
            
            // DEBUG: Log hash comparison details
            config_log(&config, &format!("üîç HASH DEBUG [Thread-{}]: File: {}", thread_id, filename.cyan()));
            config_log(&config, &format!("üîç HASH DEBUG [Thread-{}]: Key: {}", thread_id, key.cyan()));
            config_log(&config, &format!("üîç HASH DEBUG [Thread-{}]: Size: {}, ModTime: {}", thread_id, initial_size, mod_time.timestamp()));
            config_log(&config, &format!("üîç HASH DEBUG [Thread-{}]: Current hash: {}", thread_id, current_hash));
            
            // Check if we have an existing hash and if it matches
            if let Some(existing_hash) = existing_hashes.get(&key) {
                config_log(&config, &format!("üîç HASH DEBUG [Thread-{}]: Existing hash: {}", thread_id, existing_hash));
                config_log(&config, &format!("üîç HASH DEBUG [Thread-{}]: Hash match: {}", thread_id, *existing_hash == current_hash));
                
                if *existing_hash == current_hash {
                    config_log(&config, &format!("{} [Thread-{}] {} unchanged, skipping download", 
                        "‚è≠Ô∏è".yellow(), 
                        thread_id.to_string().cyan(), 
                        filename.green()
                    ));
                    
                    let _ = status_tx.send(StatusUpdate {
                        stage: "Skipped (unchanged)".to_string(),
                        filename: filename.clone(),
                        progress: file_progress + 0.15,
                        thread_id,
                        file_size: None,
                    });
                    
                    // Increment counter for skipped files
                    files_processed.fetch_add(1, Ordering::SeqCst);
                    
                    // No need to quit here - will be handled at end of retry loop
                    return Ok(()); // Skip this file
                } else {
                    config_log(&config, &format!("{} [Thread-{}] {} hash changed, will download", 
                        "üîÑ".blue(), 
                        thread_id.to_string().cyan(), 
                        filename.yellow()
                    ));
                }
            } else {
                config_log(&config, &format!("üîç HASH DEBUG [Thread-{}]: No existing hash found for key: {}", thread_id, key.cyan()));
            }
        }

        // DEBUG: Log before download attempt
        config_log(&config, &format!("‚¨áÔ∏è DEBUG: [Thread-{}] Starting download of {} ({} bytes) from '{}'", 
            thread_id, filename.cyan(), initial_size, remote_dir.cyan()));
        
        // Download file with proper mode detection
        let download_start = std::time::Instant::now();
        let download_result = download_file(&mut ftp, filename, remote_dir, &config.local_download_path, config.respect_file_paths, initial_size as u64);
        
        match download_result {
            Ok(_local_path) => {
                let _ = status_tx.send(StatusUpdate {
                    stage: "Downloaded".to_string(),
                    filename: filename.clone(),
                    progress: file_progress + 0.15,
                    thread_id,
                    file_size: Some(initial_size as u64),
                });

                let _ = status_tx.send(StatusUpdate {
                    stage: "Verified".to_string(),
                    filename: filename.clone(),
                    progress: file_progress + 0.2,
                    thread_id,
                    file_size: Some(initial_size as u64),
                });

                // Send structured notification for successful download (no progress bar)
                let _ = send_notification(&config, "success", &format!("Downloaded {}", filename), None, None);
                
                // Log download completion
                config_log(&config, &format!("{} [Thread-{}] {} downloaded successfully", 
                    "‚¨áÔ∏è".blue(), 
                    thread_id.to_string().cyan(), 
                    filename.green()
                ));
                
                // Update session state with download time and file size
                let download_time = download_start.elapsed().as_secs_f64();
                if let Ok(mut state) = session_state_clone.lock() {
                    state.add_file_download(initial_size as usize, download_time);
                    
                    // Debug logging for session stats
                    config_log(&config, &format!("üìä [Thread-{}] Session stats updated: {} files, {} bytes, {:.2}s, {:.2} MB/s avg", 
                        thread_id.to_string().cyan(),
                        state.total_files.to_string().green(),
                        state.total_bytes.to_string().blue(),
                        state.total_download_time.to_string().yellow(),
                        state.get_average_speed_mbps().to_string().cyan()
                    ));
                    
                    // Send session report only when we have meaningful data (files processed)
                    // This preserves the last valid speed until new files are processed
                    if state.total_files > 0 && state.total_files % 3 == 0 {
                        if let Err(e) = send_session_report(&session_file, &config, &state) {
                            config_log(&config, &format!("‚ö†Ô∏è [Thread-{}] Failed to send session report: {}", 
                                thread_id.to_string().yellow(), 
                                e.to_string().yellow()
                            ));
                        }
                    }
                }
                
                // Handle file based on download mode
                if config.download_mode == "keep" {
                    // Save hash to database for keep mode
                    // Get file modification time for hash computation
                    let mod_time = match get_file_mod_time(&mut ftp, filename) {
                        Ok(time) => time,
                        Err(_) => chrono::Utc::now(), // Fallback to current time
                    };
                    let file_hash = compute_file_hash(filename, remote_dir, initial_size as u64, mod_time);

                    if let Err(e) = db::save_hash(&config.session_id, remote_dir, filename, initial_size as u64, mod_time, file_hash) {
                        config_log(&config, &format!("{} [Thread-{}] Failed to save hash to database for {}: {}",
                            "‚ö†Ô∏è".yellow(),
                            thread_id.to_string().yellow(),
                            filename.yellow(),
                            e.to_string().yellow()
                        ));
                    }
                    
                    // Don't delete from server in keep mode
                    config_log(&config, &format!("{} [Thread-{}] {} kept on server (keep mode)", 
                        "üíæ".blue(), 
                        thread_id.to_string().cyan(), 
                        filename.green()
                    ));
                } else {
                    // Delete from server in delete mode
                    if let Ok(_) = ftp.rm(filename) {
                        config_log(&config, &format!("{} [Thread-{}] {} deleted from server", 
                            "üóëÔ∏è".green(), 
                            thread_id.to_string().cyan(), 
                            filename.green()
                        ));
                    } else {
                        config_log(&config, &format!("{} [Thread-{}] Failed to delete {} from server", 
                            "‚ö†Ô∏è".yellow(), 
                            thread_id.to_string().yellow(), 
                            filename.yellow()
                        ));
                    }
                }
                
                // Calculate download speed for this file
                let download_time = download_start.elapsed().as_secs_f64();
                let speed_mbps = if download_time > 0.0 {
                    (initial_size as f64 / 1024.0 / 1024.0) / download_time
                } else {
                    0.0
                };
                
                // Log completion for debugging but don't overwrite main status file
                config_log(&config_arc_local, &format!("‚úÖ Downloaded: {} ({:.2} MB at {:.2} MB/s in {:.1}s)", 
                    filename, 
                    initial_size as f64 / 1024.0 / 1024.0,
                    speed_mbps, 
                    download_time
                ));
                
                // Send completion via status channel (will be processed by status receiver thread)
                let _ = status_tx.send(StatusUpdate {
                    stage: "FileComplete".to_string(), // Use different stage to avoid confusion
                    filename: format!("‚úÖ Downloaded: {} ({:.2} MB at {:.2} MB/s in {:.1}s)", 
                        filename,
                        initial_size as f64 / 1024.0 / 1024.0,
                        speed_mbps, 
                        download_time
                    ),
                    progress: file_progress + 0.25,
                    thread_id,
                    file_size: Some(initial_size as u64),
                });
                
                let _ = status_tx.send(StatusUpdate {
                    stage: "Complete".to_string(),
                    filename: filename.clone(),
                    progress: file_progress + 0.25,
                    thread_id,
                    file_size: Some(initial_size as u64),
                });
                
                // Increment counter
                let current_count = files_processed.fetch_add(1, Ordering::SeqCst) + 1;
                config_log(&config, &format!("{} [Thread-{}] Progress: {}/{} files completed", 
                    "üìà".blue(), 
                    thread_id.to_string().cyan(), 
                    current_count.to_string().green(), 
                    files_to_process.len().to_string().yellow()
                ));
            }
            Err(e) => {
                let error_msg = format!("Download failed: {}", e);
                config_log(&config, &format!("{} [Thread-{}] Download failed for {}: {}", 
                    "‚ùå".red(), 
                    thread_id.to_string().red(), 
                    filename.red(), 
                    e.to_string().red()
                ));
                
                // Record download failure and check if we should retry
                let (is_server_rejection, retry_delay) = connection_manager_local.record_failure(&error_msg, config.sync_interval);
                
                let _ = status_tx.send(StatusUpdate {
                    stage: "Download failed".to_string(),
                    filename: filename.clone(),
                    progress: file_progress,
                    thread_id,
                    file_size: None,
                });
                
                // Clean up connection and check if we should retry
                ftp.quit().ok();
                
                if connection_attempt >= max_connection_retries {
                    config_log(&config, &format!("{} [Thread-{}] Max download retries ({}) reached for {}, giving up", 
                        "‚ùå".red(), thread_id, max_connection_retries, filename.red()));
                    break Err(format!("Download failed after {} attempts: {}", max_connection_retries, e));
                }
                
                config_log(&config, &format!("{} [Thread-{}] Will retry download for {} in {:.1}s (attempt {})", 
                    "üîÑ".yellow(), thread_id, filename.yellow(), retry_delay.as_secs_f64(), connection_attempt + 1));
                std::thread::sleep(retry_delay);
                continue; // Retry the entire file processing (connection + download)
            }
        }

            // Record successful connection for this file
            connection_manager_local.record_success();
            
            ftp.quit().ok();
            config_log(&config, &format!("{} [Thread-{}] Completed processing {} (connection restored)", 
                "üéâ".green(), 
                thread_id.to_string().cyan(), 
                filename.green()
            ));
            break Ok(()); // Successfully processed file, exit retry loop
        };
        
        file_result
        }).collect()
    });

    // Close status channel
    drop(status_tx);
    
    // Wait for status receiver to finish
    let _ = status_receiver.join();

    // Process results to count successes and failures
    let successful_files = results.iter().filter(|r| r.is_ok()).count();
    let failed_files = results.iter().filter(|r| r.is_err()).count();
    
    // Log detailed results for failed files
    let failed_file_names: Vec<String> = results.iter().enumerate()
        .filter_map(|(index, result)| {
            if let Err(error) = result {
                let (filename, _) = &files_to_process[index];
                Some(format!("{} ({})", filename, error))
            } else {
                None
            }
        })
        .collect();
    
    // Get final count from counter (should match successful_files)
    let final_count = files_processed.load(Ordering::SeqCst);

    config_log(&config, &format!("{}", "=".repeat(80).blue()));
    config_log(&config, &format!("{} Processing completed!", "üéØ".green()));
    config_log(&config, &format!("{} Files processed: {}/{} ({} successful, {} failed)", 
        "üìä".blue(), 
        successful_files.to_string().green(), 
        files_to_process.len().to_string().yellow(),
        successful_files.to_string().green(),
        failed_files.to_string().red()
    ));
    
    // Log failed files if any
    if !failed_file_names.is_empty() {
        config_log(&config, &format!("{} Failed files will be retried in next cycle:", "üîÑ".yellow()));
        for failed_file in &failed_file_names {
            config_log(&config, &format!("  ‚ùå {}", failed_file.red()));
        }
    }
    
    config_log(&config, &format!("{}", "=".repeat(80).blue()));
    
    // Send completion status with clear success/failure breakdown
    let status_message = if failed_files > 0 {
        format!("Processed {}/{} files ({} failed, will retry next cycle)", successful_files, files_to_process.len(), failed_files)
    } else {
        format!("Processed {} files successfully", successful_files)
    };
    
    send_status(status_file, &config, "Finished", &status_message, 1.0, None)?;
    
    // Send final session report only if files were processed successfully
    // This preserves the last valid speed until new files are processed
    if let Ok(state) = session_state.lock() {
        if state.total_files > 0 {
            if let Err(e) = send_session_report(session_file, &config, &state) {
                config_log(&config, &format!("‚ö†Ô∏è Failed to send final session report: {}", e.to_string().yellow()));
            }
        } else {
            config_log(&config, &format!("üìä No final session report - no files processed"));
        }
    }
    
    // Return successful count - cycle completes even with failures
    Ok(successful_files)
}

fn send_status(status_file: &str, config: &FTPConfig, stage: &str, filename: &str, progress: f64, file_size: Option<u64>) -> Result<(), Box<dyn std::error::Error>> {
    send_status_with_speed(status_file, config, stage, filename, progress, file_size, None, None)
}

fn send_notification(config: &FTPConfig, notification_type: &str, message: &str, filename: Option<&str>, progress: Option<f64>) -> Result<(), Box<dyn std::error::Error>> {
    let notification = FTPNotification {
        config_id: config.config_id,
        notification_type: notification_type.to_string(),
        message: message.to_string(),
        timestamp: chrono::Utc::now().timestamp_millis() as u64,
        filename: filename.map(|f| f.to_string()),
        progress,
    };

    // Create notifications file path using config_id hash for FFI communication
    let tmp_dir = std::env::var("FTP_TMP_DIR").unwrap_or_else(|_| "/tmp".to_string());
    let tmp_dir = tmp_dir.trim_end_matches('/');
    // Use hash for filename to match FFI expectations
    let config_hash = (config.config_id as i64).wrapping_abs() as u32;
    let notifications_file = format!("{}/ftp_notifications_{}.jsonl", tmp_dir, config_hash);

    // Append notification as JSON line
    let json_line = serde_json::to_string(&notification)?;
    let mut file = std::fs::OpenOptions::new()
        .create(true)
        .append(true)
        .open(&notifications_file)?;

    use std::io::Write;
    writeln!(file, "{}", json_line)?;

    Ok(())
}

fn send_status_with_speed(status_file: &str, config: &FTPConfig, stage: &str, filename: &str, progress: f64, file_size: Option<u64>, download_speed_mbps: Option<f64>, download_time_secs: Option<f64>) -> Result<(), Box<dyn std::error::Error>> {
    let status = FTPStatus {
        config_id: config.config_id,
        stage: stage.to_string(),
        filename: filename.to_string(),
        progress,
        timestamp: std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)?
            .as_secs(),
        file_size,
        download_speed_mbps,
        download_time_secs,
    };

    let status_json = serde_json::to_string(&status)?;
    fs::write(status_file, status_json)?;
    
    // Only log to console for important stages
    if stage == "Complete" || stage == "Error" || stage == "Warning" {
        info!("[{}] {} ‚Üí {} ({:.1}%)", config.config_name, stage, filename, progress * 100.0);
    }
    Ok(())
}

fn send_session_report(session_file: &str, config: &FTPConfig, session_state: &SessionState) -> Result<(), Box<dyn std::error::Error>> {
    let report = SessionReport {
        session_id: config.session_id.clone(),
        config_id: config.config_id,
        total_files: session_state.total_files,
        total_bytes: session_state.total_bytes,
        total_time_secs: session_state.total_download_time,
        average_speed_mbps: session_state.get_average_speed_mbps(),
    };

    let report_json = serde_json::to_string_pretty(&report)?;
    fs::write(session_file, report_json)?;
    
    // Log the session report - always show it, even if stats are 0
    if session_state.total_files > 0 {
        config_log(config, &format!("üìä Session Report: {} files, {:.2} MB/s", 
            session_state.total_files.to_string().green(),
            session_state.get_average_speed_mbps().to_string().cyan()
        ));

        println!("üîÑ LOOP RESTART: Session complete, restarting loop for next iteration");
    } else {
        config_log(config, &format!("üìä Session Report: No files processed (0 files, 0.00 MB/s)"));

        println!("üîÑ LOOP RESTART: No files processed, restarting loop for next iteration");
    }
    
    Ok(())
}

fn write_result(result_file: &str, config: &FTPConfig, success: bool, message: &str, files_processed: usize) -> Result<(), Box<dyn std::error::Error>> {
    let result = FTPResult {
        config_id: config.config_id,
        success,
        message: message.to_string(),
        files_processed,
        timestamp: std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)?
            .as_secs(),
    };

    let result_json = serde_json::to_string(&result)?;
    fs::write(result_file, result_json)?;
    Ok(())
}

// Helper function to download files with proper mode detection
fn download_file(ftp: &mut ftp::FtpStream, filename: &str, remote_dir: &str, local_dir: &str, respect_file_paths: bool, expected_size: u64) -> Result<PathBuf, Box<dyn std::error::Error>> {
    println!("üîç DOWNLOAD DEBUG: Starting download_file for {} from {}", filename, remote_dir);
    
    // Detect if file is likely text or binary based on extension
    let is_text_file = is_likely_text_file(filename);
    
    println!("üîç DOWNLOAD DEBUG: File {} detected as {}", filename, if is_text_file { "TEXT" } else { "BINARY" });
    
    // Set transfer mode based on file type
    if is_text_file {
        println!("üîç DOWNLOAD DEBUG: Setting ASCII mode for {}", filename);
        ftp.transfer_type(ftp::types::FileType::Ascii(ftp::types::FormatControl::Default))?;
    } else {
        println!("üîç DOWNLOAD DEBUG: Setting BINARY mode for {}", filename);
        ftp.transfer_type(ftp::types::FileType::Binary)?;
    }
    
    // Create local path based on respect_file_paths setting
    let local_path = if respect_file_paths && remote_dir != "/" {
        // Create directory structure by joining local_dir with remote_dir (excluding root)
        let remote_path = remote_dir.trim_start_matches('/');
        let local_path = PathBuf::from(local_dir).join(remote_path).join(filename);
        local_path
    } else {
        // Flat structure - just put file directly in local_dir
        PathBuf::from(local_dir).join(filename)
    };
    
    // Ensure directory exists
    if let Some(parent) = local_path.parent() {
        fs::create_dir_all(parent)?;
    }
    
    // Handle existing files - append _# if file exists
    let final_path = get_unique_filename(&local_path);
    let temp_path = if final_path != local_path {
        // Create temporary path with . prefix for safe download
        let temp_name = format!(".{}", final_path.file_name().unwrap().to_string_lossy());
        final_path.with_file_name(temp_name)
    } else {
        // Create temporary path with . prefix for safe download
        let temp_name = format!(".{}", filename);
        local_path.with_file_name(temp_name)
    };
    
    // Construct full remote path for RETR command
    let remote_path = if remote_dir == "/" {
        format!("/{}", filename)
    } else {
        format!("{}/{}", remote_dir.trim_end_matches('/'), filename)
    };

    println!("üîç DOWNLOAD DEBUG: About to send RETR command for full path: {}", remote_path);

    // Download file to temporary location
    let data = match ftp.retr(&remote_path, |stream| {
        println!("üîç DOWNLOAD DEBUG: RETR command accepted, reading data stream for {}", remote_path);
        let mut buffer = Vec::new();
        let result = stream.read_to_end(&mut buffer);
        println!("üîç DOWNLOAD DEBUG: Read {} bytes from stream for {}", buffer.len(), filename);
        Ok(result.map(|_| buffer).unwrap_or_default())
    }) {
        Ok(data) => {
            println!("üîç DOWNLOAD DEBUG: RETR successful for {}, got {} bytes", remote_path, data.len());
            data
        },
        Err(e) => {
            println!("‚ùå DOWNLOAD DEBUG: RETR FAILED for {}: {}", remote_path, e);
            return Err(Box::new(e));
        }
    };
    
    // CRITICAL: Verify download size matches expected size
    if data.len() as u64 != expected_size {
        // Clean up temp file if size mismatch
        let _ = fs::remove_file(&temp_path);
        return Err(format!("Download size mismatch: expected {} bytes, got {} bytes", expected_size, data.len()).into());
    }
    
    // Write to temporary file first
    fs::write(&temp_path, data)?;
    
    // Verify the written file size matches expected size
    if let Ok(metadata) = fs::metadata(&temp_path) {
        if metadata.len() != expected_size {
            // Clean up temp file if written size mismatch
            let _ = fs::remove_file(&temp_path);
            return Err(format!("Written file size mismatch: expected {} bytes, got {} bytes", expected_size, metadata.len()).into());
        }
    } else {
        // Clean up temp file if can't read metadata
        let _ = fs::remove_file(&temp_path);
        return Err("Failed to read written file metadata".into());
    }
    
    // Move temporary file to final location (atomic operation)
    fs::rename(&temp_path, &final_path)?;
    
    // Final verification: check final file size
    if let Ok(metadata) = fs::metadata(&final_path) {
        if metadata.len() != expected_size {
            // Clean up final file if size still wrong
            let _ = fs::remove_file(&final_path);
            return Err(format!("Final file size mismatch: expected {} bytes, got {} bytes", expected_size, metadata.len()).into());
        }
    } else {
        // Clean up final file if can't read metadata
        let _ = fs::remove_file(&final_path);
        return Err("Failed to read final file metadata".into());
    }
    
    // Reset to binary mode for next file
    ftp.transfer_type(ftp::types::FileType::Binary)?;
    
    Ok(final_path)
}

// Helper function to get unique filename (append _# if file exists)
fn get_unique_filename(path: &PathBuf) -> PathBuf {
    if !path.exists() {
        return path.clone();
    }
    
    let mut counter = 1;
    let stem = path.file_stem().unwrap().to_string_lossy();
    let extension = path.extension().map(|ext| format!(".{}", ext.to_string_lossy())).unwrap_or_default();
    
    loop {
        let new_name = format!("{}_{}{}", stem, counter, extension);
        let new_path = path.with_file_name(new_name);
        
        if !new_path.exists() {
            return new_path;
        }
        
        counter += 1;
        
        // Prevent infinite loop (max 999 files)
        if counter > 999 {
            break;
        }
    }
    
    // Fallback: append timestamp
    let timestamp = std::time::SystemTime::now()
        .duration_since(std::time::UNIX_EPOCH)
        .unwrap()
        .as_secs();
    let new_name = format!("{}_{}{}", stem, timestamp, extension);
    path.with_file_name(new_name)
}

// Helper function to detect if a file is likely text
fn is_likely_text_file(filename: &str) -> bool {
    let text_extensions = [
        "txt", "md", "json", "xml", "html", "htm", "css", "js", "py", "rs", "swift", "java", "c", "cpp", "h", "hpp",
        "sh", "bash", "zsh", "fish", "ps1", "bat", "cmd", "ini", "cfg", "conf", "log", "csv", "tsv", "sql", "r", "m",
        "tex", "bib", "tex", "sty", "cls", "ltx", "dtx", "ins", "fdt", "fdb", "aux", "bbl", "blg", "idx", "ind", "glo",
        "acn", "alg", "ist", "loa", "lot", "out", "toc", "lof", "lol", "nav", "snm", "vrb", "synctex.gz"
    ];
    
    if let Some(extension) = filename.split('.').last() {
        text_extensions.contains(&extension.to_lowercase().as_str())
    } else {
        false
    }
}
